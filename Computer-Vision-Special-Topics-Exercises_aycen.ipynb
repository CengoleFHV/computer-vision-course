{"cells":[{"cell_type":"markdown","metadata":{"id":"p9CP8BWhLtvJ"},"source":["# Computer Vision - Special Topics\n","\n","This notebook contains exercises for the Computer Vision Special Topics material."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"a2mBfycbLtvL"},"source":["### Exercise 1 - Transfer Learning\n","\n","**Summary:**\n","In this exercise we will use transfer learning using a neural networks outputs as features for a SVM.\n","\n","**Data**:\n","We will use a subset of the cifar100 dataset (I call it cifar20). You are provided with a pre-trained model on the cifar80 (the other categories in cifar100) that reaches a test\n","accuracy of approximately 63% on the cifar80 dataset. Execute the cells below to prepare the dataset and load the pretrained model (```pretrained_model```). Notice that the pretrained model was trained\n","for a 80-class problem.  \n","\n","**Your Tasks in this exercise:**\n","\n","1. Use transfer learning to train a SVM classifier using the features extracted by the pretrained model\n","    * Extract features using a suitable layer in the pretrained model. Notice you might want to use the ```tf.keras.Model(inputs=, outputs=)``` class to access the outputs of each layer easily.\n","    * Train a SVM classifier (use sklearn) on the features extracted using the training data (```X_train_cifar20```)\n","    * Evaluate the performance of your classifier on the features extracted using the test data (```X_test_cifar20```)\n","    * Discuss your results.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1712839888110,"user":{"displayName":"Cengole","userId":"15358946546147421967"},"user_tz":-120},"id":"k6nhbiTXLtvM"},"outputs":[],"source":["(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar100.load_data()\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","cifar20_labels = np.array([60, 72, 65, 97, 18, 47, 58, 51, 84,  2, 90,  6, 38, 35, 70, 89, 24, 86, 36, 32])\n","cifar20_label_mapping = {60 : 0, 72: 1, 65 : 2, 97 : 3, 18 : 4, 47 : 5, 58 : 6, 51 : 7, 84 : 8,  2 : 9, 90 : 10,\n","                          6 : 11, 38 : 12, 35 :13, 70 : 14, 89 : 15, 24 : 16, 86 : 17, 36: 18, 32 : 19}\n","\n","X_train_cifar20 = X_train[np.isin(Y_train, cifar20_labels).ravel(),:,:]\n","Y_train_cifar20 = Y_train[np.isin(Y_train, cifar20_labels).ravel()]\n","\n","X_test_cifar20 = X_test[np.isin(Y_test, cifar20_labels).ravel(),:,:]\n","Y_test_cifar20 = Y_test[np.isin(Y_test, cifar20_labels).ravel()]\n","\n","\n","Y_train_cifar20_remapped = []\n","for y in Y_train_cifar20.ravel():\n","    y_mapped = cifar20_label_mapping[y]\n","    Y_train_cifar20_remapped.append(y_mapped)\n","Y_train_cifar20 = np.array(Y_train_cifar20_remapped)\n","\n","Y_test_cifar20_remapped = []\n","for y in Y_test_cifar20.ravel():\n","    y_mapped = cifar20_label_mapping[y]\n","    Y_test_cifar20_remapped.append(y_mapped)\n","Y_test_cifar20 = np.array(Y_test_cifar20_remapped)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJha3jzLLtvN","outputId":"de3c7944-59dc-4a59-c61e-97e5e37c4978"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-03-22 15:44:13--  https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/cifar80_resnet_best.h5\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/cifar80_resnet_best.h5 [following]\n","--2023-03-22 15:44:13--  https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/cifar80_resnet_best.h5\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 34199344 (33M) [application/octet-stream]\n","Saving to: â€˜../data/cifar80_resnet_best.h5.3â€™\n","\n","cifar80_resnet_best 100%[===================>]  32.61M  87.0MB/s    in 0.4s    \n","\n","2023-03-22 15:44:14 (87.0 MB/s) - â€˜../data/cifar80_resnet_best.h5.3â€™ saved [34199344/34199344]\n","\n"]}],"source":["!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/cifar80_resnet_best.h5 -P ../data\n","pretrained = tf.keras.models.load_model('../data/cifar80_resnet_best.h5')"]},{"cell_type":"markdown","metadata":{"id":"6GDnNOppLtvO"},"source":["### Exercise 2 - Fine Tuning\n","\n","**Summary:**\n","In this exercise we will use fine tuning to adapt a neural network to a new dataset.\n","\n","**Data**:\n","We will use a subset of the cifar100 dataset (I call it cifar20). You are provided with a pre-trained model on the cifar80 (the other categories in cifar100) that reaches a test\n","accuracy of approximately 63% on the cifar80 dataset. Execute the cells below to prepare the dataset and load the pretrained model (```pretrained_model```). Notice that the pretrained model was trained\n","for a 80-class problem.  \n","\n","**Your Tasks in this exercise:**\n","\n","1. Fine tune the pre-trained model.\n","    * Create a new model using the functional keras API that uses the pretrained model in a 20-class classification problem. Notice you will need to ignore/remove the final layer and replace it with a suitable layer.\n","    * Train your fine-tuning model:\n","        * Freeze all layers borrowed from the pre-trained model and and fine tune the model\n","        * Fine-tune all layers of the new model\n","        * Compare both models.\n","    * Plot and discuss your results.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y2JWp7nNLtvP","outputId":"a7b2285f-4fbe-4754-a79c-981d9324e0c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-03-22 15:35:13--  https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/cifar80_resnet_best.h5\n","Resolving github.com (github.com)... 140.82.121.3\n","Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/cifar80_resnet_best.h5 [following]\n","--2023-03-22 15:35:13--  https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/cifar80_resnet_best.h5\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 34199344 (33M) [application/octet-stream]\n","Saving to: â€˜../data/cifar80_resnet_best.h5.2â€™\n","\n","cifar80_resnet_best 100%[===================>]  32.61M  62.7MB/s    in 0.5s    \n","\n","2023-03-22 15:35:14 (62.7 MB/s) - â€˜../data/cifar80_resnet_best.h5.2â€™ saved [34199344/34199344]\n","\n"]}],"source":["!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/cifar80_resnet_best.h5 -P ../data\n","pretrained_model = tf.keras.models.load_model('../data/cifar80_resnet_best.h5')\n","\n","import tensorflow as tf\n","import numpy as np\n","\n","(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar100.load_data()\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","cifar20_labels = np.array([60, 72, 65, 97, 18, 47, 58, 51, 84,  2, 90,  6, 38, 35, 70, 89, 24, 86, 36, 32])\n","cifar20_label_mapping = {60 : 0, 72: 1, 65 : 2, 97 : 3, 18 : 4, 47 : 5, 58 : 6, 51 : 7, 84 : 8,  2 : 9, 90 : 10,\n","                          6 : 11, 38 : 12, 35 :13, 70 : 14, 89 : 15, 24 : 16, 86 : 17, 36: 18, 32 : 19}\n","\n","X_train_cifar20 = X_train[np.isin(Y_train, cifar20_labels).ravel(),:,:]\n","Y_train_cifar20 = Y_train[np.isin(Y_train, cifar20_labels).ravel()]\n","\n","X_test_cifar20 = X_test[np.isin(Y_test, cifar20_labels).ravel(),:,:]\n","Y_test_cifar20 = Y_test[np.isin(Y_test, cifar20_labels).ravel()]\n","\n","Y_train_cifar20_remapped = []\n","for y in Y_train_cifar20.ravel():\n","    y_mapped = cifar20_label_mapping[y]\n","    Y_train_cifar20_remapped.append(y_mapped)\n","Y_train_cifar20 = np.array(Y_train_cifar20_remapped)\n","\n","Y_test_cifar20_remapped = []\n","for y in Y_test_cifar20.ravel():\n","    y_mapped = cifar20_label_mapping[y]\n","    Y_test_cifar20_remapped.append(y_mapped)\n","Y_test_cifar20 = np.array(Y_test_cifar20_remapped)\n","\n","Y_train_cifar_20_one_hot = tf.keras.utils.to_categorical(Y_train_cifar20_remapped)\n","Y_test_cifar_20_one_hot = tf.keras.utils.to_categorical(Y_test_cifar20_remapped)\n"]},{"cell_type":"markdown","metadata":{"id":"mgyvjN5XLtvR"},"source":["### Exercise 3 - Regularization Techniques\n","\n","**Summary:**\n","In this exercise we study different regularization techniques used to train neural networks.\n","\n","**Data**:\n","In this exercise we will use the cifar10 dataset. I have provided you with a cell to load and preprocess the dataset below. I also provided you with a very simple base-CNN\n","(```cnn_base```).\n","\n","**Your Tasks in this exercise:**\n","\n","1. Train and evaluate the base-CNN\n","    * Train the base-CNN on the training portion of the dataset\n","    * Make sure that the test part of the data is used after each epoch to predict the test accuracy\n","    * Record the history of your training (```hist = cnn_base.fit(...)```) and plot your results after training is finished. You can access the training accuracy values\n","    via ```hist.history['acc']``` and the test accuracy values via ```hist.history['val_acc']```.\n","    * Explain the results.\n","\n","2. Train and evaluate the base-CNN using L1-Regularization\n","    * Create a new cell and copy the base-CNN. Add a kernel regularizer and bias regularizer using L1-Regularization (where does it make sense?)\n","    * Train the L1-CNN, plot the results and compare the results to the base-CNN.\n","    * Explain the results.\n","\n","3. Train and evaluate the base-CNN using L2-Regularization\n","    * Create a new cell and copy the base-CNN. Add a kernel regularizer and bias regularizer using L2-Regularization (where does it make sense?)\n","    * Train the L2-CNN, plot the results and compare the results to the base-CNN.\n","    * Explain the results.\n","\n","4. Train and evaluate the base-CNN using Dropout\n","    * Create a new cell and copy the base-CNN. Add Dropout layers (where does it make sense?)\n","    * Train the Dropout-CNN, plot the results and compare the results to the base-CNN.\n","    * Explain the results."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"executionInfo":{"elapsed":8,"status":"error","timestamp":1712839888109,"user":{"displayName":"Cengole","userId":"15358946546147421967"},"user_tz":-120},"id":"W4BQ1gTKLtvS","outputId":"3f3ea0c7-e935-4643-8d77-2f7ffef154a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 0us/step\n"]}],"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0\n","\n","y_test = tf.keras.utils.to_categorical(y_test, 10)\n","y_train = tf.keras.utils.to_categorical(y_train, 10)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13772,"status":"ok","timestamp":1712839904359,"user":{"displayName":"Cengole","userId":"15358946546147421967"},"user_tz":-120},"id":"hJLGcNPfLtvT"},"outputs":[],"source":["# Use this simple CNN as your basis for adding regularization.\n","#\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, InputLayer, MaxPooling2D, GlobalAveragePooling2D, Softmax, Dense, Flatten, Dropout\n","\n","cnn_base = tf.keras.Sequential()\n","cnn_base.add(InputLayer(input_shape=(32,32,3)))\n","cnn_base.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n","cnn_base.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n","cnn_base.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n","cnn_base.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n","cnn_base.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n","cnn_base.add(MaxPooling2D(pool_size=(2,2), strides=(1,1)))\n","cnn_base.add(Flatten())\n","cnn_base.add(Dense(256, activation='relu'))\n","cnn_base.add(Dense(10, activation='softmax'))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.4293 - loss: 1.5701 - val_accuracy: 0.6035 - val_loss: 1.1203\n","Epoch 2/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.6365 - loss: 1.0340 - val_accuracy: 0.6406 - val_loss: 1.0108\n","Epoch 3/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - accuracy: 0.7092 - loss: 0.8337 - val_accuracy: 0.6617 - val_loss: 0.9862\n","Epoch 4/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.7584 - loss: 0.6880 - val_accuracy: 0.6848 - val_loss: 0.9382\n","Epoch 5/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - accuracy: 0.8105 - loss: 0.5350 - val_accuracy: 0.6802 - val_loss: 0.9914\n","Epoch 6/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - accuracy: 0.8611 - loss: 0.3985 - val_accuracy: 0.6789 - val_loss: 1.1236\n","Epoch 7/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.8980 - loss: 0.2918 - val_accuracy: 0.6643 - val_loss: 1.3230\n","Epoch 8/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9277 - loss: 0.2123 - val_accuracy: 0.6606 - val_loss: 1.5088\n","Epoch 9/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.9403 - loss: 0.1731 - val_accuracy: 0.6524 - val_loss: 1.6766\n","Epoch 10/10\n","\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - accuracy: 0.9498 - loss: 0.1456 - val_accuracy: 0.6442 - val_loss: 1.9725\n"]}],"source":["cnn_base.compile(\n","    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",")\n","\n","history = cnn_base.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"]},{"cell_type":"markdown","metadata":{"id":"rGJkXFkMLtvW"},"source":["### Exercise 4 - Residual Learning\n","\n","**Summary:**\n","In this exercise we will create two neural networks that take an image with shape $(32,32,3)$ as input and provide us with the same image as output $(32,32,3)$. Consequently we try to learn a mapping $\\mathcal{H}(x) := x$, which is known as the identity function. The identity function is a trivial function in mathematics but can be hard to learn using convolution operations.\n","\n","**Data**:\n","In this exercise we will use the cifar100 dataset. I have provided you with a cell to load and preprocess the dataset below.\n","\n","**Your Tasks in this exercise:**\n","\n","1. ConvNet\n","    * Create a convolutional neural network (with 2 BatchNormalization and Conv2D layers, using only InputLayer, Conv2D and BatchNormalization as layers), which accepts images of shape $(32,32,3)$ and returns an image of shape $(32,32,3)$. Notice: You will have to use the functional keras API to do so (see slides).\n","    * Train your neural network (use only 2 epochs) with a suitable loss function.  \n","2. ResNet\n","    * Create a convolutional neural network using two identity blocks of a ResNet, which accepts images of shape $(32,32,3)$ and returns an image of shape $(32,32,3)$.\n","    * Train your neural network (using only 2 epochs) with a suitable loss function.\n","3. Analyze your Results\n","    * Use the ```evaluate()``` function of your keras model to predict the MSE of both trained nets.\n","    * Use some images from ```X_test``` and feed them into your models. Visualize the results.\n","    * Compare the results, explain the difference between the results, explain what happened.\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQ9d4YO5LtvW"},"outputs":[],"source":["(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0"]}],"metadata":{"celltoolbar":"Edit Metadata","colab":{"provenance":[{"file_id":"https://github.com/shegenbart/Jupyter-Exercises/blob/main/Computer-Vision-Special-Topics/Computer-Vision-Special-Topics-Exercises.ipynb","timestamp":1712839862092}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
